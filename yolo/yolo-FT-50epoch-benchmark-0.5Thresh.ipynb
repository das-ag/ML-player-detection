{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6e952f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO  # Ensure you have `pip install ultralytics`\n",
    "import random\n",
    "\n",
    "\n",
    "# --- CONFIG ---\n",
    "# DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\") \n",
    "BASE_DATA_ROOT = \"../soccernet_data/tracking\"\n",
    "GT_FILENAME = \"gt.txt\"\n",
    "IMAGE_FOLDER = \"img1\"\n",
    "IMAGE_EXTS = ['.jpg', '.png']\n",
    "NUM_VISUALS = 10\n",
    "SCORE_THRESH = 0.5\n",
    "IOU_THRESH = 0.5\n",
    "SAMPLE_PER_SEQ = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a46abf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Processing sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequences:   0%|          | 0/106 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 18 players, 1 referee, 48.9ms\n",
      "Speed: 2.4ms preprocess, 48.9ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 players, 1 referee, 15.2ms\n",
      "Speed: 2.1ms preprocess, 15.2ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 goalkeeper, 15 players, 2 referees, 17.9ms\n",
      "Speed: 2.1ms preprocess, 17.9ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 players, 1 referee, 15.8ms\n",
      "Speed: 2.1ms preprocess, 15.8ms inference, 14.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 players, 2 referees, 16.2ms\n",
      "Speed: 1.9ms preprocess, 16.2ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 goalkeeper, 15 players, 2 referees, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 12.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 players, 15.4ms\n",
      "Speed: 2.1ms preprocess, 15.4ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 ball, 23 players, 1 referee, 15.6ms\n",
      "Speed: 2.1ms preprocess, 15.6ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 ball, 20 players, 2 referees, 15.8ms\n",
      "Speed: 2.2ms preprocess, 15.8ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 players, 16.6ms\n",
      "Speed: 2.3ms preprocess, 16.6ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 players, 1 referee, 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 goalkeeper, 11 players, 1 referee, 16.3ms\n",
      "Speed: 2.6ms preprocess, 16.3ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 players, 15.2ms\n",
      "Speed: 2.5ms preprocess, 15.2ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 players, 2 referees, 15.0ms\n",
      "Speed: 14.1ms preprocess, 15.0ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 goalkeeper, 13 players, 2 referees, 14.1ms\n",
      "Speed: 2.0ms preprocess, 14.1ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 players, 2 referees, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 goalkeeper, 11 players, 1 referee, 15.9ms\n",
      "Speed: 2.1ms preprocess, 15.9ms inference, 14.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 goalkeeper, 14 players, 2 referees, 16.2ms\n",
      "Speed: 2.7ms preprocess, 16.2ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 goalkeeper, 14 players, 2 referees, 16.7ms\n",
      "Speed: 2.2ms preprocess, 16.7ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 players, 1 referee, 15.8ms\n",
      "Speed: 1.9ms preprocess, 15.8ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 players, 2 referees, 16.7ms\n",
      "Speed: 2.4ms preprocess, 16.7ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 2 referees, 15.7ms\n",
      "Speed: 2.7ms preprocess, 15.7ms inference, 14.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 players, 2 referees, 14.9ms\n",
      "Speed: 2.5ms preprocess, 14.9ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 players, 1 referee, 14.8ms\n",
      "Speed: 2.1ms preprocess, 14.8ms inference, 12.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 players, 1 referee, 15.1ms\n",
      "Speed: 1.9ms preprocess, 15.1ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 players, 2 referees, 15.9ms\n",
      "Speed: 2.3ms preprocess, 15.9ms inference, 14.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 players, 2 referees, 16.3ms\n",
      "Speed: 3.0ms preprocess, 16.3ms inference, 14.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 goalkeeper, 10 players, 3 referees, 14.3ms\n",
      "Speed: 2.3ms preprocess, 14.3ms inference, 14.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 2 referees, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 ball, 1 goalkeeper, 15 players, 1 referee, 14.6ms\n",
      "Speed: 2.2ms preprocess, 14.6ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequences:   1%|          | 1/106 [00:05<10:17,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 13 players, 30.6ms\n",
      "Speed: 2.2ms preprocess, 30.6ms inference, 14.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 players, 2 referees, 15.3ms\n",
      "Speed: 2.1ms preprocess, 15.3ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 ball, 20 players, 2 referees, 17.2ms\n",
      "Speed: 2.1ms preprocess, 17.2ms inference, 14.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 ball, 7 players, 16.9ms\n",
      "Speed: 2.8ms preprocess, 16.9ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 ball, 19 players, 1 referee, 16.8ms\n",
      "Speed: 2.2ms preprocess, 16.8ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 players, 1 referee, 58.3ms\n",
      "Speed: 2.3ms preprocess, 58.3ms inference, 19.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 players, 3 referees, 15.6ms\n",
      "Speed: 2.3ms preprocess, 15.6ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 players, 15.6ms\n",
      "Speed: 1.8ms preprocess, 15.6ms inference, 14.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 goalkeeper, 16 players, 2 referees, 15.9ms\n",
      "Speed: 2.2ms preprocess, 15.9ms inference, 15.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 players, 16.3ms\n",
      "Speed: 2.6ms preprocess, 16.3ms inference, 14.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 players, 2 referees, 15.5ms\n",
      "Speed: 2.1ms preprocess, 15.5ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 players, 15.5ms\n",
      "Speed: 1.9ms preprocess, 15.5ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 players, 2 referees, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 players, 15.6ms\n",
      "Speed: 2.1ms preprocess, 15.6ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 players, 17.3ms\n",
      "Speed: 10.7ms preprocess, 17.3ms inference, 14.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 players, 1 referee, 15.1ms\n",
      "Speed: 2.2ms preprocess, 15.1ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 players, 2 referees, 119.8ms\n",
      "Speed: 33.2ms preprocess, 119.8ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 16.3ms\n",
      "Speed: 2.2ms preprocess, 16.3ms inference, 14.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 players, 17.6ms\n",
      "Speed: 2.1ms preprocess, 17.6ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 players, 1 referee, 17.5ms\n",
      "Speed: 2.8ms preprocess, 17.5ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 players, 16.2ms\n",
      "Speed: 2.2ms preprocess, 16.2ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 goalkeeper, 19 players, 1 referee, 15.2ms\n",
      "Speed: 1.9ms preprocess, 15.2ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 players, 15.2ms\n",
      "Speed: 2.1ms preprocess, 15.2ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 players, 1 referee, 15.9ms\n",
      "Speed: 2.2ms preprocess, 15.9ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 players, 4 referees, 16.4ms\n",
      "Speed: 2.2ms preprocess, 16.4ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 ball, 10 players, 1 referee, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 players, 1 referee, 17.4ms\n",
      "Speed: 2.6ms preprocess, 17.4ms inference, 97.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 12.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 16.8ms\n",
      "Speed: 2.3ms preprocess, 16.8ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 players, 2 referees, 15.8ms\n",
      "Speed: 2.5ms preprocess, 15.8ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequences:   2%|▏         | 2/106 [00:11<09:56,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 16 players, 1 referee, 35.0ms\n",
      "Speed: 2.1ms preprocess, 35.0ms inference, 23.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 players, 2 referees, 15.3ms\n",
      "Speed: 2.3ms preprocess, 15.3ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 players, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 18.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 players, 2 referees, 17.2ms\n",
      "Speed: 2.0ms preprocess, 17.2ms inference, 14.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 players, 1 referee, 14.4ms\n",
      "Speed: 2.0ms preprocess, 14.4ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 ball, 16 players, 2 referees, 14.6ms\n",
      "Speed: 2.6ms preprocess, 14.6ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 players, 14.3ms\n",
      "Speed: 2.0ms preprocess, 14.3ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 players, 13.9ms\n",
      "Speed: 2.4ms preprocess, 13.9ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 ball, 20 players, 1 referee, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 players, 1 referee, 14.3ms\n",
      "Speed: 2.5ms preprocess, 14.3ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 players, 2 referees, 14.7ms\n",
      "Speed: 2.1ms preprocess, 14.7ms inference, 12.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 players, 1 referee, 13.8ms\n",
      "Speed: 2.0ms preprocess, 13.8ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 players, 2 referees, 14.3ms\n",
      "Speed: 1.9ms preprocess, 14.3ms inference, 22.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 players, 14.2ms\n",
      "Speed: 2.3ms preprocess, 14.2ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 players, 15.0ms\n",
      "Speed: 2.4ms preprocess, 15.0ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 ball, 16 players, 2 referees, 14.7ms\n",
      "Speed: 2.0ms preprocess, 14.7ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 players, 2 referees, 14.5ms\n",
      "Speed: 2.2ms preprocess, 14.5ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 players, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 players, 1 referee, 14.3ms\n",
      "Speed: 2.0ms preprocess, 14.3ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 players, 2 referees, 14.1ms\n",
      "Speed: 2.0ms preprocess, 14.1ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 players, 1 referee, 14.3ms\n",
      "Speed: 2.0ms preprocess, 14.3ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 players, 1 referee, 15.8ms\n",
      "Speed: 2.1ms preprocess, 15.8ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 players, 1 referee, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 players, 1 referee, 17.2ms\n",
      "Speed: 2.1ms preprocess, 17.2ms inference, 15.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 players, 1 referee, 17.6ms\n",
      "Speed: 2.3ms preprocess, 17.6ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 ball, 21 players, 1 referee, 15.8ms\n",
      "Speed: 2.8ms preprocess, 15.8ms inference, 14.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 ball, 23 players, 14.9ms\n",
      "Speed: 2.1ms preprocess, 14.9ms inference, 14.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 players, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 players, 16.0ms\n",
      "Speed: 2.5ms preprocess, 16.0ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 players, 3 referees, 14.8ms\n",
      "Speed: 2.6ms preprocess, 14.8ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequences:   3%|▎         | 3/106 [00:17<09:55,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 17 players, 3 referees, 35.2ms\n",
      "Speed: 2.2ms preprocess, 35.2ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 players, 2 referees, 15.2ms\n",
      "Speed: 2.5ms preprocess, 15.2ms inference, 14.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 players, 2 referees, 14.9ms\n",
      "Speed: 2.0ms preprocess, 14.9ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 players, 3 referees, 14.8ms\n",
      "Speed: 2.2ms preprocess, 14.8ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 players, 1 referee, 15.8ms\n",
      "Speed: 2.1ms preprocess, 15.8ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 players, 3 referees, 14.2ms\n",
      "Speed: 2.2ms preprocess, 14.2ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 ball, 26 players, 2 referees, 14.3ms\n",
      "Speed: 2.0ms preprocess, 14.3ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 players, 2 referees, 15.4ms\n",
      "Speed: 2.6ms preprocess, 15.4ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 players, 1 referee, 15.9ms\n",
      "Speed: 1.9ms preprocess, 15.9ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 players, 1 referee, 14.6ms\n",
      "Speed: 1.9ms preprocess, 14.6ms inference, 14.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 players, 2 referees, 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 14.8ms\n",
      "Speed: 2.2ms preprocess, 14.8ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 players, 1 referee, 15.7ms\n",
      "Speed: 2.7ms preprocess, 15.7ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 ball, 22 players, 1 referee, 15.2ms\n",
      "Speed: 2.4ms preprocess, 15.2ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 players, 3 referees, 15.6ms\n",
      "Speed: 2.3ms preprocess, 15.6ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 goalkeeper, 20 players, 2 referees, 15.4ms\n",
      "Speed: 2.1ms preprocess, 15.4ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 players, 16.1ms\n",
      "Speed: 2.4ms preprocess, 16.1ms inference, 14.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 players, 2 referees, 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 ball, 21 players, 2 referees, 16.6ms\n",
      "Speed: 2.7ms preprocess, 16.6ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 players, 2 referees, 14.9ms\n",
      "Speed: 2.0ms preprocess, 14.9ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 players, 2 referees, 15.9ms\n",
      "Speed: 2.2ms preprocess, 15.9ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 players, 2 referees, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 15.9ms\n",
      "Speed: 2.0ms preprocess, 15.9ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 2 referees, 15.9ms\n",
      "Speed: 2.3ms preprocess, 15.9ms inference, 14.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 players, 3 referees, 15.4ms\n",
      "Speed: 2.4ms preprocess, 15.4ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 players, 14.8ms\n",
      "Speed: 2.1ms preprocess, 14.8ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 players, 1 referee, 16.5ms\n",
      "Speed: 2.1ms preprocess, 16.5ms inference, 14.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 players, 4 referees, 16.8ms\n",
      "Speed: 2.2ms preprocess, 16.8ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 players, 2 referees, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 players, 2 referees, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 14.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequences:   4%|▍         | 4/106 [00:22<09:35,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 21 players, 2 referees, 35.4ms\n",
      "Speed: 2.1ms preprocess, 35.4ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 players, 3 referees, 17.4ms\n",
      "Speed: 2.4ms preprocess, 17.4ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 players, 2 referees, 18.7ms\n",
      "Speed: 2.4ms preprocess, 18.7ms inference, 15.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 players, 2 referees, 16.6ms\n",
      "Speed: 2.4ms preprocess, 16.6ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 players, 2 referees, 16.4ms\n",
      "Speed: 2.2ms preprocess, 16.4ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 players, 2 referees, 14.3ms\n",
      "Speed: 2.4ms preprocess, 14.3ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 players, 1 referee, 16.5ms\n",
      "Speed: 2.8ms preprocess, 16.5ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 goalkeeper, 16 players, 1 referee, 15.2ms\n",
      "Speed: 2.1ms preprocess, 15.2ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 players, 18.8ms\n",
      "Speed: 2.4ms preprocess, 18.8ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 players, 2 referees, 16.4ms\n",
      "Speed: 2.3ms preprocess, 16.4ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 players, 2 referees, 15.4ms\n",
      "Speed: 2.4ms preprocess, 15.4ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 players, 2 referees, 15.2ms\n",
      "Speed: 2.0ms preprocess, 15.2ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 players, 1 referee, 15.7ms\n",
      "Speed: 2.2ms preprocess, 15.7ms inference, 18.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 players, 1 referee, 16.5ms\n",
      "Speed: 3.4ms preprocess, 16.5ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 players, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 players, 15.2ms\n",
      "Speed: 2.1ms preprocess, 15.2ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 players, 2 referees, 15.3ms\n",
      "Speed: 2.2ms preprocess, 15.3ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 players, 2 referees, 14.6ms\n",
      "Speed: 2.2ms preprocess, 14.6ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 players, 1 referee, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 14.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 players, 2 referees, 15.3ms\n",
      "Speed: 2.1ms preprocess, 15.3ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 players, 1 referee, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 14.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 players, 3 referees, 15.8ms\n",
      "Speed: 2.0ms preprocess, 15.8ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 players, 2 referees, 15.9ms\n",
      "Speed: 2.2ms preprocess, 15.9ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 goalkeeper, 22 players, 15.6ms\n",
      "Speed: 2.2ms preprocess, 15.6ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 players, 16.6ms\n",
      "Speed: 2.1ms preprocess, 16.6ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 players, 1 referee, 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 14.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 players, 1 referee, 15.3ms\n",
      "Speed: 2.3ms preprocess, 15.3ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 ball, 20 players, 2 referees, 17.3ms\n",
      "Speed: 2.3ms preprocess, 17.3ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 players, 2 referees, 16.0ms\n",
      "Speed: 2.2ms preprocess, 16.0ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 28 players, 2 referees, 15.4ms\n",
      "Speed: 2.3ms preprocess, 15.4ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequences:   5%|▍         | 5/106 [00:29<10:05,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 8 players, 1 referee, 35.8ms\n",
      "Speed: 2.3ms preprocess, 35.8ms inference, 67.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 players, 1 referee, 15.7ms\n",
      "Speed: 2.2ms preprocess, 15.7ms inference, 9.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 players, 1 referee, 14.9ms\n",
      "Speed: 1.9ms preprocess, 14.9ms inference, 14.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 players, 1 referee, 14.7ms\n",
      "Speed: 2.2ms preprocess, 14.7ms inference, 15.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 players, 3 referees, 18.9ms\n",
      "Speed: 2.6ms preprocess, 18.9ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 players, 1 referee, 17.8ms\n",
      "Speed: 2.8ms preprocess, 17.8ms inference, 14.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 goalkeeper, 23 players, 1 referee, 16.7ms\n",
      "Speed: 2.1ms preprocess, 16.7ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 goalkeeper, 22 players, 1 referee, 15.6ms\n",
      "Speed: 2.1ms preprocess, 15.6ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 goalkeeper, 23 players, 2 referees, 15.7ms\n",
      "Speed: 2.0ms preprocess, 15.7ms inference, 9.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 players, 2 referees, 15.9ms\n",
      "Speed: 2.1ms preprocess, 15.9ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 players, 1 referee, 15.5ms\n",
      "Speed: 2.3ms preprocess, 15.5ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 players, 15.2ms\n",
      "Speed: 2.5ms preprocess, 15.2ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 players, 1 referee, 15.7ms\n",
      "Speed: 2.2ms preprocess, 15.7ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequences:   5%|▍         | 5/106 [00:33<11:24,  6.77s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 122\u001b[0m\n\u001b[1;32m    119\u001b[0m gt_boxes \u001b[38;5;241m=\u001b[39m gt_dict\u001b[38;5;241m.\u001b[39mget(frame_id, [])\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 122\u001b[0m     yolo_result \u001b[38;5;241m=\u001b[39m model(img)[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Get first result\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     preds \u001b[38;5;241m=\u001b[39m yolo_result\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mto(DEVICE) \u001b[38;5;28;01mif\u001b[39;00m yolo_result\u001b[38;5;241m.\u001b[39mboxes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m6\u001b[39m))\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m    125\u001b[0m pred_boxes \u001b[38;5;241m=\u001b[39m preds[:, :\u001b[38;5;241m4\u001b[39m][preds[:, \u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m>\u001b[39m SCORE_THRESH] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(preds) \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m4\u001b[39m), device\u001b[38;5;241m=\u001b[39mDEVICE)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML_FinalProj/lib/python3.11/site-packages/ultralytics/engine/model.py:181\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    154\u001b[0m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, Image\u001b[38;5;241m.\u001b[39mImage, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    155\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    157\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    158\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source, stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML_FinalProj/lib/python3.11/site-packages/ultralytics/engine/model.py:549\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor(source\u001b[38;5;241m=\u001b[39msource, stream\u001b[38;5;241m=\u001b[39mstream)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML_FinalProj/lib/python3.11/site-packages/ultralytics/engine/predictor.py:218\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML_FinalProj/lib/python3.11/site-packages/torch/utils/_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML_FinalProj/lib/python3.11/site-packages/ultralytics/engine/predictor.py:336\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;66;03m# Postprocess\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m2\u001b[39m]:\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(preds, im, im0s)\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_predict_postprocess_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# Visualize, save, write results\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML_FinalProj/lib/python3.11/site-packages/ultralytics/models/yolo/detect/predict.py:55\u001b[0m, in \u001b[0;36mDetectionPredictor.postprocess\u001b[0;34m(self, preds, img, orig_imgs, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03mPost-process predictions and return a list of Results objects.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    >>> processed_results = predictor.postprocess(preds, img, orig_imgs)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m save_feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_feats\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 55\u001b[0m preds \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mnon_max_suppression(\n\u001b[1;32m     56\u001b[0m     preds,\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mconf,\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39miou,\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mclasses,\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39magnostic_nms,\n\u001b[1;32m     61\u001b[0m     max_det\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmax_det,\n\u001b[1;32m     62\u001b[0m     nc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnames),\n\u001b[1;32m     63\u001b[0m     end2end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend2end\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m     64\u001b[0m     rotated\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     65\u001b[0m     return_idxs\u001b[38;5;241m=\u001b[39msave_feats,\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(orig_imgs, \u001b[38;5;28mlist\u001b[39m):  \u001b[38;5;66;03m# input images are a torch.Tensor, not a list\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     orig_imgs \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_torch2numpy_batch(orig_imgs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML_FinalProj/lib/python3.11/site-packages/ultralytics/utils/ops.py:289\u001b[0m, in \u001b[0;36mnon_max_suppression\u001b[0;34m(prediction, conf_thres, iou_thres, classes, agnostic, multi_label, labels, max_det, nc, max_time_img, max_nms, max_wh, in_place, rotated, end2end, return_idxs)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# Detections matrix nx6 (xyxy, conf, cls)\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m box, \u001b[38;5;28mcls\u001b[39m, mask \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msplit((\u001b[38;5;241m4\u001b[39m, nc, nm), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_label:\n\u001b[1;32m    292\u001b[0m     i, j \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(\u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m>\u001b[39m conf_thres)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML_FinalProj/lib/python3.11/site-packages/torch/_tensor.py:1038\u001b[0m, in \u001b[0;36mTensor.split\u001b[0;34m(self, split_size, dim)\u001b[0m\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Resize\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Resize\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mself\u001b[39m, tensor\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 1038\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, split_size, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"See :func:`torch.split`\"\"\"\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- LOAD MODEL ---\n",
    "model = YOLO(\"discovery-runs/detect/ft-50epoch/weights/best.pt\").to(DEVICE)\n",
    "# model.half().to(DEVICE)\n",
    "# model.to(DEVICE)\n",
    "\n",
    "transform = T.ToTensor()\n",
    "\n",
    "def load_gt_boxes(gt_path):\n",
    "    gt_dict = defaultdict(list)\n",
    "    if not os.path.exists(gt_path):\n",
    "        return gt_dict\n",
    "    with open(gt_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(',')\n",
    "            frame, _, x, y, w, h, cls, _, _ = map(int, parts[:9])\n",
    "            gt_dict[frame].append(torch.tensor([x, y, x + w, y + h], device=DEVICE))\n",
    "    return gt_dict\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    if box1.size(0) == 0 or box2.size(0) == 0:\n",
    "        return torch.zeros((box1.size(0), box2.size(0)), device=box1.device)\n",
    "    area1 = (box1[:, 2] - box1[:, 0]) * (box1[:, 3] - box1[:, 1])\n",
    "    area2 = (box2[:, 2] - box2[:, 0]) * (box2[:, 3] - box2[:, 1])\n",
    "    lt = torch.max(box1[:, None, :2], box2[:, :2])\n",
    "    rb = torch.min(box1[:, None, 2:], box2[:, 2:])\n",
    "    wh = (rb - lt).clamp(min=0)\n",
    "    inter = wh[:, :, 0] * wh[:, :, 1]\n",
    "    union = area1[:, None] + area2 - inter\n",
    "    iou = inter / union\n",
    "    return iou\n",
    "\n",
    "def plot_gt_and_detections(image_tensor, detections, gt_boxes):\n",
    "    from torchvision.utils import draw_bounding_boxes\n",
    "    all_boxes = []\n",
    "    labels = []\n",
    "    colors = []\n",
    "\n",
    "    for box in detections:\n",
    "        all_boxes.append(box)\n",
    "        labels.append(\"pred\")\n",
    "        colors.append(\"red\")\n",
    "\n",
    "    for box in gt_boxes:\n",
    "        all_boxes.append(box)\n",
    "        labels.append(\"gt\")\n",
    "        colors.append(\"green\")\n",
    "\n",
    "    if not all_boxes:\n",
    "        return T.ToPILImage()(image_tensor)\n",
    "    \n",
    "    boxes_tensor = torch.stack(all_boxes).cpu()\n",
    "\n",
    "    \n",
    "    x1 = torch.min(boxes_tensor[:, 0], boxes_tensor[:, 2])\n",
    "    y1 = torch.min(boxes_tensor[:, 1], boxes_tensor[:, 3])\n",
    "    x2 = torch.max(boxes_tensor[:, 0], boxes_tensor[:, 2])\n",
    "    y2 = torch.max(boxes_tensor[:, 1], boxes_tensor[:, 3])\n",
    "    boxes_tensor = torch.stack([x1, y1, x2, y2], dim=1).to(torch.int)\n",
    "    img_uint8 = (image_tensor * 255).byte().cpu()\n",
    "    drawn = draw_bounding_boxes(img_uint8, boxes_tensor, labels=labels, colors=colors, width=2)\n",
    "    return T.ToPILImage()(drawn)\n",
    "\n",
    "# --- EXECUTION ---\n",
    "results = []\n",
    "sample_frames = []\n",
    "total_tp = total_fp = total_fn = 0\n",
    "\n",
    "seq_dirs = []\n",
    "for split in [\"train\", \"test\"]:\n",
    "    split_dir = os.path.join(BASE_DATA_ROOT, split)\n",
    "    if not os.path.exists(split_dir):\n",
    "        continue\n",
    "    for d in sorted(os.listdir(split_dir)):\n",
    "        full_path = os.path.join(split_dir, d)\n",
    "        if os.path.isdir(full_path):\n",
    "            seq_dirs.append((split, d))\n",
    "\n",
    "print(\"Using device:\", DEVICE)\n",
    "print(\"Processing sequences...\")\n",
    "\n",
    "for split, seq_id in tqdm(seq_dirs, desc=\"Sequences\", dynamic_ncols=True):\n",
    "    seq_path = os.path.join(BASE_DATA_ROOT, split, seq_id)\n",
    "    img_dir = os.path.join(seq_path, IMAGE_FOLDER)\n",
    "    gt_path = os.path.join(seq_path, \"gt\", GT_FILENAME)\n",
    "    gt_dict = load_gt_boxes(gt_path)\n",
    "\n",
    "    if not os.path.exists(img_dir):\n",
    "        continue\n",
    "\n",
    "    all_img_paths = sorted([\n",
    "        os.path.join(img_dir, file)\n",
    "        for file in os.listdir(img_dir)\n",
    "        if any(file.lower().endswith(ext) for ext in IMAGE_EXTS)\n",
    "    ])\n",
    "\n",
    "    random.shuffle(all_img_paths)\n",
    "    all_img_paths = all_img_paths[:SAMPLE_PER_SEQ]\n",
    "\n",
    "    for path in all_img_paths:\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        img_tensor = transform(img).unsqueeze(0)\n",
    "        img_tensor = img_tensor.half()\n",
    "        img_tensor = img_tensor.squeeze(0) \n",
    "\n",
    "        img_tensor = img_tensor.to(DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "        filename = os.path.basename(path)\n",
    "        try:\n",
    "            frame_id = int(filename.split('.')[0])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        gt_boxes = gt_dict.get(frame_id, [])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            yolo_result = model(img)[0]  # Get first result\n",
    "            preds = yolo_result.boxes.data.to(DEVICE) if yolo_result.boxes is not None else torch.empty((0, 6)).to(DEVICE)\n",
    "\n",
    "        pred_boxes = preds[:, :4][preds[:, 4] > SCORE_THRESH] if len(preds) else torch.empty((0, 4), device=DEVICE)\n",
    "\n",
    "        # Accuracy\n",
    "        if gt_boxes:\n",
    "            gt_tensor = torch.stack(gt_boxes).to(DEVICE)\n",
    "            if len(pred_boxes) > 0:\n",
    "                ious = compute_iou(pred_boxes, gt_tensor)\n",
    "                max_ious = ious.max(dim=1)[0]\n",
    "                acc = (max_ious > IOU_THRESH).float().mean().item()\n",
    "            else:\n",
    "                acc = 0.0\n",
    "        else:\n",
    "            acc = 1.0 if len(pred_boxes) == 0 else 0.0\n",
    "\n",
    "        results.append(acc)\n",
    "\n",
    "        # Precision/Recall\n",
    "        matched_gt = set()\n",
    "        tp = fp = 0\n",
    "        if len(pred_boxes) > 0 and len(gt_boxes) > 0:\n",
    "            ious = compute_iou(pred_boxes, gt_tensor)\n",
    "            for i in range(len(pred_boxes)):\n",
    "                max_iou, gt_idx = ious[i].max(0)\n",
    "                if max_iou > IOU_THRESH and gt_idx.item() not in matched_gt:\n",
    "                    tp += 1\n",
    "                    matched_gt.add(gt_idx.item())\n",
    "                else:\n",
    "                    fp += 1\n",
    "        else:\n",
    "            tp = 0\n",
    "            fp = len(pred_boxes)\n",
    "\n",
    "        fn = len(gt_boxes) - len(matched_gt)\n",
    "        total_tp += tp\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "\n",
    "        if len(sample_frames) < NUM_VISUALS and seq_id not in [s[0] for s in sample_frames]:\n",
    "            img_vis = plot_gt_and_detections(img_tensor, pred_boxes, gt_boxes)\n",
    "            sample_frames.append((seq_id, filename, img_vis))\n",
    "            \n",
    "\n",
    "# --- METRICS ---\n",
    "precision = total_tp / (total_tp + total_fp + 1e-6)\n",
    "recall = total_tp / (total_tp + total_fn + 1e-6)\n",
    "avg_acc = sum(results) / len(results) if results else 0\n",
    "print(f\"\\nAverage Detection Accuracy over {len(results)} frames: {avg_acc * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}\")\n",
    "\n",
    "# --- SHOW EXAMPLES ---\n",
    "for seq_id, filename, img in sample_frames:\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Sequence {seq_id}, Frame {filename}\\nRed = Prediction, Green = Ground Truth\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208bc702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_FinalProj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
