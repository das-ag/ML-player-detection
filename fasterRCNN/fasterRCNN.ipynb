{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb96af4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Faster R-CNN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bada/anaconda3/envs/practice/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/bada/anaconda3/envs/practice/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fasterrcnn_pretrained_test.ipynb\n",
    "# Purpose: Use pretrained Faster R-CNN to detect players on SoccerNet dataset frames\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- CONFIG ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BASE_DATA_DIR = \"../soccernet_data/tracking/test\"\n",
    "GT_FILENAME = \"gt.txt\"\n",
    "IMAGE_FOLDER = \"img1\"\n",
    "IMAGE_EXTS = ['.jpg', '.png']\n",
    "NUM_OUTPUT_SAMPLE_IMAGES = 10\n",
    "SCORE_THRESH = 0.8\n",
    "IOU_THRESH = 0.5\n",
    "\n",
    "# --- LOAD MODEL ---\n",
    "print(\"Loading Faster R-CNN model...\")\n",
    "\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()\n",
    "model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b296618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- IMAGE PREPROCESSING ---\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "def load_gt_boxes(gt_path):\n",
    "    gt_dict = defaultdict(list)\n",
    "    if not os.path.exists(gt_path):\n",
    "        return gt_dict\n",
    "    with open(gt_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(',')\n",
    "            frame, _, x, y, w, h, cls, _, _ = map(int, parts[:9])\n",
    "            box = torch.tensor([x, y, x + w, y + h], device=DEVICE)\n",
    "            gt_dict[frame].append(box)\n",
    "    return gt_dict\n",
    "\n",
    "# --- IOU CALCULATION ---\n",
    "def compute_iou(box1, box2):\n",
    "    if box1.size(0) == 0 or box2.size(0) == 0:\n",
    "        return torch.zeros((box1.size(0), box2.size(0)), device=box1.device)\n",
    "    area1 = (box1[:, 2] - box1[:, 0]) * (box1[:, 3] - box1[:, 1])\n",
    "    area2 = (box2[:, 2] - box2[:, 0]) * (box2[:, 3] - box2[:, 1])\n",
    "    lt = torch.max(box1[:, None, :2], box2[:, :2])\n",
    "    rb = torch.min(box1[:, None, 2:], box2[:, 2:])\n",
    "    wh = (rb - lt).clamp(min=0)\n",
    "    inter = wh[:, :, 0] * wh[:, :, 1]\n",
    "    union = area1[:, None] + area2 - inter\n",
    "    iou = inter / union\n",
    "    return iou\n",
    "\n",
    "# --- DRAW DETECTIONS + GT ---\n",
    "def plot_gt_and_detections(image_tensor, detections, gt_boxes, score_thresh=0.8):\n",
    "    boxes = detections['boxes']\n",
    "    scores = detections['scores']\n",
    "    keep = scores > score_thresh\n",
    "    pred_boxes = boxes[keep]\n",
    "\n",
    "    all_boxes = []\n",
    "    labels = []\n",
    "    colors = []\n",
    "\n",
    "    for box in pred_boxes:\n",
    "        all_boxes.append(box)\n",
    "        labels.append(\"pred\")\n",
    "        colors.append(\"red\")\n",
    "\n",
    "    for box in gt_boxes:\n",
    "        all_boxes.append(box)\n",
    "        labels.append(\"gt\")\n",
    "        colors.append(\"green\")\n",
    "\n",
    "    if len(all_boxes) == 0:\n",
    "        return T.ToPILImage()(image_tensor)\n",
    "\n",
    "    all_boxes_tensor = torch.stack(all_boxes).to(\"cpu\")\n",
    "    drawn = draw_bounding_boxes(\n",
    "        (image_tensor * 255).byte().cpu(),\n",
    "        boxes=all_boxes_tensor,\n",
    "        labels=labels,\n",
    "        colors=colors,\n",
    "        width=2\n",
    "    )\n",
    "    return T.ToPILImage()(drawn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "643291f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of images to sample: 10\n",
      "Score threshold: 0.8\n",
      "IOU threshold: 0.5\n",
      "Processing sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequences: 100%|██████████| 106/106 [04:54<00:00,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sampled frames to output: 10\n",
      "Total frames processed: 3180\n",
      "Final metrics:\n",
      "\n",
      "Average Detection Accuracy over 3180 frames: 87.13%\n",
      "Precision: 0.867, Recall: 0.839 frames: 87.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sequence_usage_frame_count = 30\n",
    "\n",
    "print(\"Using device:\", DEVICE)\n",
    "print(\"Number of images to sample:\", NUM_OUTPUT_SAMPLE_IMAGES)\n",
    "print(\"Score threshold:\", SCORE_THRESH)\n",
    "print(\"IOU threshold:\", IOU_THRESH)\n",
    "\n",
    "# --- EXECUTION ---\n",
    "results = []\n",
    "sample_frames = []\n",
    "total_tp = total_fp = total_fn = 0\n",
    "\n",
    "# Include both train and test sequences\n",
    "seq_dirs = []\n",
    "for split in [\"train\", \"test\"]:\n",
    "    split_dir = os.path.join(\"../soccernet_data/tracking\", split)\n",
    "    if not os.path.exists(split_dir):\n",
    "        continue\n",
    "    for d in sorted(os.listdir(split_dir)):\n",
    "        full_path = os.path.join(split_dir, d)\n",
    "        if os.path.isdir(full_path):\n",
    "            seq_dirs.append((split, d))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Processing sequences...\")\n",
    "# Get 30 random frames from each sequence\n",
    "for split, seq_id in tqdm(seq_dirs, desc=\"Sequences\", dynamic_ncols=True):\n",
    "    seq_path = os.path.join(\"../soccernet_data/tracking\", split, seq_id)\n",
    "    img_dir = os.path.join(seq_path, IMAGE_FOLDER)\n",
    "    gt_path = os.path.join(seq_path, \"gt\", GT_FILENAME)\n",
    "    gt_dict = load_gt_boxes(gt_path)\n",
    "\n",
    "    if not os.path.exists(img_dir):\n",
    "        continue\n",
    "\n",
    "    all_img_paths = sorted([\n",
    "        os.path.join(img_dir, file)\n",
    "        for file in os.listdir(img_dir)\n",
    "        if any(file.lower().endswith(ext) for ext in IMAGE_EXTS)\n",
    "    ])[:30]  # Randomized below\n",
    "\n",
    "    random.shuffle(all_img_paths)  # Shuffle to get random frames\n",
    "    all_img_paths = all_img_paths[:sequence_usage_frame_count]  # Sample random frames from each sequence\n",
    "\n",
    "    for idx, path in enumerate(all_img_paths):\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping corrupted image: {path} | Error: {e}\")\n",
    "            continue\n",
    "\n",
    "        img_tensor = transform(img).unsqueeze(0).to(DEVICE)\n",
    "        filename = os.path.basename(path)\n",
    "\n",
    "        try:\n",
    "            frame_id = int(filename.split('.')[0])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        \n",
    "        gt_boxes = gt_dict.get(frame_id, [])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(img_tensor.to(DEVICE))[0]\n",
    "\n",
    "        pred_boxes = output['boxes'][output['scores'] > SCORE_THRESH]\n",
    "\n",
    "\n",
    "        # Accuracy\n",
    "        if gt_boxes:\n",
    "            gt_tensor = torch.stack(gt_boxes).to(DEVICE)\n",
    "            if len(pred_boxes) > 0:\n",
    "                ious = compute_iou(pred_boxes, gt_tensor)\n",
    "                max_ious = ious.max(dim=1)[0]\n",
    "                acc = (max_ious > IOU_THRESH).float().mean().item()\n",
    "            else:\n",
    "                acc = 0.0\n",
    "        else:\n",
    "            acc = 1.0 if len(pred_boxes) == 0 else 0.0\n",
    "\n",
    "        results.append(acc)\n",
    "\n",
    "\n",
    "        # Precision / Recall\n",
    "        matched_gt = set()\n",
    "        tp = fp = 0\n",
    "        if len(pred_boxes) > 0 and len(gt_boxes) > 0:\n",
    "            gt_tensor = torch.stack(gt_boxes).to(DEVICE)\n",
    "            ious = compute_iou(pred_boxes, gt_tensor)\n",
    "            for i in range(len(pred_boxes)):\n",
    "                max_iou, gt_idx = ious[i].max(0)\n",
    "                if max_iou > IOU_THRESH and gt_idx.item() not in matched_gt:\n",
    "                    tp += 1\n",
    "                    matched_gt.add(gt_idx.item())\n",
    "                else:\n",
    "                    fp += 1\n",
    "        else:\n",
    "            tp = 0\n",
    "            fp = len(pred_boxes)\n",
    "\n",
    "        fn = len(gt_boxes) - len(matched_gt)\n",
    "        total_tp += tp\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "\n",
    "        # Sampled frames\n",
    "        if len(sample_frames) < NUM_OUTPUT_SAMPLE_IMAGES and seq_id not in [s[0] for s in sample_frames]:\n",
    "            img_vis = plot_gt_and_detections(img_tensor[0], output, gt_boxes)\n",
    "            sample_frames.append((seq_id, filename, img_vis))\n",
    "\n",
    "# --- DISPLAY SUMMARY ---\n",
    "print(f\"Number of sampled frames to output: {len(sample_frames)}\")\n",
    "print(f\"Total frames processed: {len(results)}\")\n",
    "\n",
    "print(\"Final metrics:\")\n",
    "# Final metrics\n",
    "precision = total_tp / (total_tp + total_fp + 1e-6)\n",
    "recall = total_tp / (total_tp + total_fn + 1e-6)\n",
    "avg_acc = sum(results) / len(results) if results else 0\n",
    "print(f\"\\nAverage Detection Accuracy over {len(results)} frames: {avg_acc * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.3f}, Recall: {recall:.3f} frames: {avg_acc * 100:.2f}%\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "482cd092",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for seq_id, filename, img in sample_frames:\n",
    "    img.save(os.path.join(\"baseline_imgs/8-5\", f\"{seq_id}_{filename}\"))\n",
    "\n",
    "# Save metrics\n",
    "# os.makedirs(\"metrics\", exist_ok=True)\n",
    "with open(\"baseline_imgs/8-5/metrics.txt\", \"w\") as f:\n",
    "    f.write(f\"Score Threshold: {SCORE_THRESH}\\n\")\n",
    "    f.write(f\"IOU Threshold: {IOU_THRESH}\\n\")\n",
    "    f.write(f\"Total frames processed: {len(results)}\\n\")\n",
    "    f.write(f\"Average Detection Accuracy: {avg_acc * 100:.2f}%\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}, Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"Total TP: {total_tp}, Total FP: {total_fp}, Total FN: {total_fn}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecac2bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of images to sample: 10\n",
      "Score threshold: 0.5\n",
      "IOU threshold: 0.5\n",
      "Processing sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequences: 100%|██████████| 106/106 [04:59<00:00,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sampled frames to output: 10\n",
      "Total frames processed: 3180\n",
      "Final metrics:\n",
      "\n",
      "Average Detection Accuracy over 3180 frames: 70.05%\n",
      "Precision: 0.681, Recall: 0.880 frames: 70.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "SCORE_THRESH = 0.5\n",
    "IOU_THRESH = 0.5\n",
    "\n",
    "import random\n",
    "\n",
    "sequence_usage_frame_count = 30\n",
    "\n",
    "print(\"Using device:\", DEVICE)\n",
    "print(\"Number of images to sample:\", NUM_OUTPUT_SAMPLE_IMAGES)\n",
    "print(\"Score threshold:\", SCORE_THRESH)\n",
    "print(\"IOU threshold:\", IOU_THRESH)\n",
    "\n",
    "# --- EXECUTION ---\n",
    "results = []\n",
    "sample_frames = []\n",
    "total_tp = total_fp = total_fn = 0\n",
    "\n",
    "# Include both train and test sequences\n",
    "seq_dirs = []\n",
    "for split in [\"train\", \"test\"]:\n",
    "    split_dir = os.path.join(\"../soccernet_data/tracking\", split)\n",
    "    if not os.path.exists(split_dir):\n",
    "        continue\n",
    "    for d in sorted(os.listdir(split_dir)):\n",
    "        full_path = os.path.join(split_dir, d)\n",
    "        if os.path.isdir(full_path):\n",
    "            seq_dirs.append((split, d))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Processing sequences...\")\n",
    "# Get 30 random frames from each sequence\n",
    "for split, seq_id in tqdm(seq_dirs, desc=\"Sequences\", dynamic_ncols=True):\n",
    "    seq_path = os.path.join(\"../soccernet_data/tracking\", split, seq_id)\n",
    "    img_dir = os.path.join(seq_path, IMAGE_FOLDER)\n",
    "    gt_path = os.path.join(seq_path, \"gt\", GT_FILENAME)\n",
    "    gt_dict = load_gt_boxes(gt_path)\n",
    "\n",
    "    if not os.path.exists(img_dir):\n",
    "        continue\n",
    "\n",
    "    all_img_paths = sorted([\n",
    "        os.path.join(img_dir, file)\n",
    "        for file in os.listdir(img_dir)\n",
    "        if any(file.lower().endswith(ext) for ext in IMAGE_EXTS)\n",
    "    ])[:30]  # Randomized below\n",
    "\n",
    "    random.shuffle(all_img_paths)  # Shuffle to get random frames\n",
    "    all_img_paths = all_img_paths[:sequence_usage_frame_count]  # Sample random frames from each sequence\n",
    "\n",
    "    for idx, path in enumerate(all_img_paths):\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping corrupted image: {path} | Error: {e}\")\n",
    "            continue\n",
    "\n",
    "        img_tensor = transform(img).unsqueeze(0).to(DEVICE)\n",
    "        filename = os.path.basename(path)\n",
    "\n",
    "        try:\n",
    "            frame_id = int(filename.split('.')[0])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        \n",
    "        gt_boxes = gt_dict.get(frame_id, [])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(img_tensor.to(DEVICE))[0]\n",
    "\n",
    "        pred_boxes = output['boxes'][output['scores'] > SCORE_THRESH]\n",
    "\n",
    "\n",
    "        # Accuracy\n",
    "        if gt_boxes:\n",
    "            gt_tensor = torch.stack(gt_boxes).to(DEVICE)\n",
    "            if len(pred_boxes) > 0:\n",
    "                ious = compute_iou(pred_boxes, gt_tensor)\n",
    "                max_ious = ious.max(dim=1)[0]\n",
    "                acc = (max_ious > IOU_THRESH).float().mean().item()\n",
    "            else:\n",
    "                acc = 0.0\n",
    "        else:\n",
    "            acc = 1.0 if len(pred_boxes) == 0 else 0.0\n",
    "\n",
    "        results.append(acc)\n",
    "\n",
    "\n",
    "        # Precision / Recall\n",
    "        matched_gt = set()\n",
    "        tp = fp = 0\n",
    "        if len(pred_boxes) > 0 and len(gt_boxes) > 0:\n",
    "            gt_tensor = torch.stack(gt_boxes).to(DEVICE)\n",
    "            ious = compute_iou(pred_boxes, gt_tensor)\n",
    "            for i in range(len(pred_boxes)):\n",
    "                max_iou, gt_idx = ious[i].max(0)\n",
    "                if max_iou > IOU_THRESH and gt_idx.item() not in matched_gt:\n",
    "                    tp += 1\n",
    "                    matched_gt.add(gt_idx.item())\n",
    "                else:\n",
    "                    fp += 1\n",
    "        else:\n",
    "            tp = 0\n",
    "            fp = len(pred_boxes)\n",
    "\n",
    "        fn = len(gt_boxes) - len(matched_gt)\n",
    "        total_tp += tp\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "\n",
    "        # Sampled frames\n",
    "        if len(sample_frames) < NUM_OUTPUT_SAMPLE_IMAGES and seq_id not in [s[0] for s in sample_frames]:\n",
    "            img_vis = plot_gt_and_detections(img_tensor[0], output, gt_boxes)\n",
    "            sample_frames.append((seq_id, filename, img_vis))\n",
    "\n",
    "# --- DISPLAY SUMMARY ---\n",
    "print(f\"Number of sampled frames to output: {len(sample_frames)}\")\n",
    "print(f\"Total frames processed: {len(results)}\")\n",
    "\n",
    "print(\"Final metrics:\")\n",
    "# Final metrics\n",
    "precision = total_tp / (total_tp + total_fp + 1e-6)\n",
    "recall = total_tp / (total_tp + total_fn + 1e-6)\n",
    "avg_acc = sum(results) / len(results) if results else 0\n",
    "print(f\"\\nAverage Detection Accuracy over {len(results)} frames: {avg_acc * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.3f}, Recall: {recall:.3f} frames: {avg_acc * 100:.2f}%\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7345d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save sample frames\n",
    "\n",
    "for seq_id, filename, img in sample_frames:\n",
    "    img.save(os.path.join(\"baseline_imgs/5-5\", f\"{seq_id}_{filename}\"))\n",
    "\n",
    "# Save metrics\n",
    "# os.makedirs(\"metrics\", exist_ok=True)\n",
    "with open(\"baseline_imgs/5-5/metrics.txt\", \"w\") as f:\n",
    "    f.write(f\"Score Threshold: {SCORE_THRESH}\\n\")\n",
    "    f.write(f\"IOU Threshold: {IOU_THRESH}\\n\")\n",
    "    f.write(f\"Total frames processed: {len(results)}\\n\")\n",
    "    f.write(f\"Average Detection Accuracy: {avg_acc * 100:.2f}%\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}, Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"Total TP: {total_tp}, Total FP: {total_fp}, Total FN: {total_fn}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cb0c20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
