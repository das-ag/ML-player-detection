{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bfc7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from torchvision.ops import box_convert\n",
    "\n",
    "class SoccerNetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform or T.ToTensor()\n",
    "        self.image_paths = []\n",
    "        self.targets = []\n",
    "\n",
    "        for seq_id in sorted(os.listdir(root_dir)):\n",
    "            img_dir = os.path.join(root_dir, seq_id, \"img1\")\n",
    "            gt_path = os.path.join(root_dir, seq_id, \"gt\", \"gt.txt\")\n",
    "            if not os.path.exists(gt_path): continue\n",
    "\n",
    "            # Read ground truth boxes per frame\n",
    "            gt_map = {}\n",
    "            with open(gt_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = list(map(int, line.strip().split(',')[:6]))  # frame, id, x, y, w, h\n",
    "                    frame, _, x, y, w, h = parts\n",
    "                    box = [x, y, w, h]\n",
    "                    gt_map.setdefault(frame, []).append(box)\n",
    "\n",
    "            for img_file in sorted(os.listdir(img_dir)):\n",
    "                if not img_file.lower().endswith((\".jpg\", \".png\")):\n",
    "                    continue\n",
    "                frame_id = int(img_file.split('.')[0])\n",
    "                img_path = os.path.join(img_dir, img_file)\n",
    "                boxes = gt_map.get(frame_id, [])\n",
    "\n",
    "                if len(boxes) == 0:\n",
    "                    continue\n",
    "\n",
    "                # Convert [x, y, w, h] â†’ [x1, y1, x2, y2]\n",
    "                boxes_xyxy = box_convert(torch.tensor(boxes, dtype=torch.float32), in_fmt='xywh', out_fmt='xyxy')\n",
    "                labels = torch.ones((len(boxes),), dtype=torch.int64)  # label 1 = player\n",
    "                target = {\"boxes\": boxes_xyxy, \"labels\": labels}\n",
    "                self.image_paths.append(img_path)\n",
    "                self.targets.append(target)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        img_tensor = self.transform(img)\n",
    "        return img_tensor, self.targets[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5acd6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Load pretrained model\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.train()\n",
    "model.to(\"cuda\")\n",
    "\n",
    "# Replace head (optional, but useful for fine-tuning)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes=2)\n",
    "\n",
    "# Dataset + DataLoader\n",
    "train_dataset = SoccerNetDataset(\"../soccernet_data/tracking/train\")\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "# Optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Training loop\n",
    "from tqdm import tqdm\n",
    "for epoch in range(5):  # fine-tune for 5 epochs\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, targets in tqdm(train_loader):\n",
    "        images = list(img.to(\"cuda\") for img in images)\n",
    "        targets = [{k: v.to(\"cuda\") for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += losses.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8202e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "version = \"v1.0\"\n",
    "\n",
    "torch.save(model.state_dict(), f\"fasterrcnn_finetuned_{version}.pth\")\n",
    "\n",
    "# Load\n",
    "# model.load_state_dict(torch.load(\"fasterrcnn_soccernet_finetuned.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bdd558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(epoch_losses, num_epochs):\n",
    "\n",
    "    # Plot loss\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(range(1, num_epochs+1), epoch_losses, marker='o', color='blue')\n",
    "    plt.title(\"Training Loss per Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.xticks(range(1, num_epochs+1))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
